{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3974735,"sourceType":"datasetVersion","datasetId":2358916},{"sourceId":1502302,"sourceType":"datasetVersion","datasetId":883769}],"dockerImageVersionId":30213,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T06:52:08.091744Z","iopub.execute_input":"2024-04-29T06:52:08.092275Z","iopub.status.idle":"2024-04-29T06:52:09.305764Z","shell.execute_reply.started":"2024-04-29T06:52:08.092158Z","shell.execute_reply":"2024-04-29T06:52:09.304223Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Import data\nsales = pd.read_csv('Weekly_Food_Retail_Prices.csv')\nprint(sales.shape)\nsales.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T06:53:09.037157Z","iopub.execute_input":"2024-04-29T06:53:09.037695Z","iopub.status.idle":"2024-04-29T06:53:09.068025Z","shell.execute_reply.started":"2024-04-29T06:53:09.037656Z","shell.execute_reply":"2024-04-29T06:53:09.066749Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_18/3668339340.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Weekly_Food_Retail_Prices.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Weekly_Food_Retail_Prices.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'Weekly_Food_Retail_Prices.csv'","output_type":"error"}]},{"cell_type":"code","source":"sales.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check unique values in dataset\nsales.apply(lambda x: len(x.unique()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for categorical columns\ncat_col = []\nfor x in sales.dtypes.index:\n    if sales.dtypes[x] == 'object':\n        cat_col.append(x)\ncat_col","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Defining the various categories in the 'Category' column","metadata":{}},{"cell_type":"code","source":"comm = sales['Commodity']\ncomm.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat = sales['Category']\ncat.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['Commodity'] = comm\ndf['Category'] = cat\n\n# Create DataFrame\ndff = pd.DataFrame()\ndff['Dummy'] = df['Commodity'] + \" \" +  df['Category'].astype(str)\nprint(dff)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the 'Category' column\nsales.drop(['Category'], axis=1, inplace=True)\nsales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dff.rename(columns = {'Dummy':'Category'}, inplace = True)\nprint(dff)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales = pd.concat([sales, dff], axis=1)\nsales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After extracting and joining the 2 columns, we need to define the category\ndef category(x):\n    if x == 'Apple Food' or x == 'Banana Food' or x == 'Coconut Food':\n        return 'Fruits'\n    elif x == 'Fish Food':\n        return 'Fish'\n    elif x == 'Meat Food' or x == 'Chicken Food':\n        return 'Meat'\n    elif x == 'Milk Food' or x == 'Butter Food' or x == 'Ghee Food':\n        return 'Milk products'\n    elif x == 'Potato Food' or x == 'Onion Food' or x == 'Brinjal Food' or x == 'Red Chillies Food' or x == 'Coriander Food' or x == 'Tomato Food':\n        return 'Vegetables'\n    elif x == 'Mustard Oil Food' or x == 'Groundnut Oil Food' or x == 'Coconut Oil Food' or x == 'Gingelly Oil Food':\n        return 'Oil'\n    elif x == 'Salt Food' or x == 'Sugar Food' or x == 'Gur Food' or x == 'Black Pepper Food' or x == 'Turmeric Food' or x == 'Cumin Seed Food':\n        return 'Spices'\n    elif x == 'Coffee Food' or x == 'Tea Food':\n        return 'Beverages'\n    elif x == 'Moong Food' or x == 'Urad Food' or x == 'Masur Food' or x == 'Arhar Food':\n        return 'Dal'\n    elif x == 'Jowar Food' or x == 'Maida Food' or x == 'Atta Food' or x == 'Wheat Food' or x == 'Bajra Food' or x == 'Ragi Food' or x == 'Maize Food':\n        return 'Flour'\n    else:\n        return 'Misc'\n\nsales['Category'] = sales['Category'].apply(lambda x: category(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-ordering the columns\nsales = sales.reindex(columns=['State', 'Centre', 'Category', 'Commodity', 'Variety', 'Unit', 'Date', 'Retail Price'])\nprint(sales.shape)\nsales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the retail prices of the categories\nplt.figure(figsize=(15,7))\nsns.barplot(x=sales['Category'], y=sales['Retail Price'])\nplt.xticks(rotation=\"vertical\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the retail prices of the various commodities\nplt.figure(figsize=(20,7))\nsns.barplot(x=sales['Commodity'], y=sales['Retail Price'])\nplt.xticks(rotation=\"vertical\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Get the average price of categories per state","metadata":{}},{"cell_type":"code","source":"states = ['Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Goa', 'Gujarat', 'Haryana', 'Himachal Pradesh', 'Jammu Kashmir', 'Jharkhand', 'Karnataka', 'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland',  'National Capital', 'Orissa', 'Punjab', 'Rajasthan', 'Sikkim',  'Tamil Nadu', 'Telangana', 'Tripura', 'Union Territories',  'Uttar Pradesh', 'Uttarakhand', 'West Bengal']\ncategories = ['Fruits', 'Dal', 'Flour', 'Misc', 'Vegetables', 'Spices', 'Fish', 'Milk products', 'Oil', 'Beverages', 'Meat']\n\ndef mean_retail_categories(state, category):\n    x = (sales['State'] == state)\n    y = (sales['Category'] == category)\n    \n    s1 = sales[x & y & (sales['Retail Price'] > 0)]\n    \n    for state in states:\n        for category in categories:\n            return s1['Retail Price'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calling the func with custom values\nmean_retail_categories(\"Bihar\", \"Fruits\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_retail_categories(\"Assam\", \"Fruits\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Get the average price of commodities per state","metadata":{}},{"cell_type":"code","source":"commodities = ['Apple', 'Arhar', 'Atta', 'Bajra', 'Banana', 'Besan', 'Biscuit', 'Tomato', 'Turmeric', 'Urad', 'Vanaspati', 'Wheat', 'Coriander', 'Cummin Seed', 'Eggs', 'Fish', 'Ghee', 'Gingelly Oil', 'Gram', 'Moong', 'Mustard Oil', 'Onion', 'Potato', 'Ragi', 'Red Chillies', 'Rice', 'Salt', 'Sugar', 'Suji', 'Tea', 'Black Pepper', 'Bread', 'Brinjal', 'Butter', 'Chicken', 'Coconut', 'Coconut Oil', 'Coffee', 'Groundnut Oil', 'Gur', 'Jowar', 'Maida', 'Maize', 'Masur', 'Meat', 'Milk']\nstates = ['Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Goa', 'Gujarat', 'Haryana', 'Himachal Pradesh', 'Jammu Kashmir', 'Jharkhand', 'Karnataka', 'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland',  'National Capital', 'Orissa', 'Punjab', 'Rajasthan', 'Sikkim',  'Tamil Nadu', 'Telangana', 'Tripura', 'Union Territories',  'Uttar Pradesh', 'Uttarakhand', 'West Bengal']\n\ndef mean_retail_products(state, commodity):\n    x = (sales['State'] == state)\n    y = (sales['Commodity'] == commodity)\n    \n    s2 = sales[x & y & (sales['Retail Price'] > 0)]\n    \n    for state in states:\n        for commodity in commodities:\n            return s2['Retail Price'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calling the func with custom values\nmean_retail_products(\"Bihar\", \"Apple\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_retail_products(\"Assam\", \"Apple\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Processing","metadata":{}},{"cell_type":"code","source":"# Let's check for null values\nsales.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are 890838 missing values in 'Variety', so fill it\nsales[\"Variety\"].fillna(\"FAQ\", inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales['Variety'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are 2993169 missing values in 'Retail Price', so fill it\nsales['Retail Price'] = sales['Retail Price'].fillna(sales['Retail Price'].median())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales['Retail Price'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dealing with the 'Unit' column\nsales['Unit'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales['Unit'].replace(['Kg.', 'Dozen', '80gm. Pkt', '100gm. Pkt', 'Kg/Litre', 'Kg', '250gm. Pkt','400/800 Gm', 'Peice', '500gm. Pkt', 'Litre'], [1, 1, 0.08, 0.1, 1, 1, 0.25, 0.5, 1, 0.5, 1], inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# analysing the 'Date' column\nsales['Date'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataFrame\ndate = sales['Date']\n\ndf = pd.DataFrame()\ndf['date'] = date\nprint(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split column into multiple columns by delimiter \ndf[['Date', 'Month', 'Year']] = df['date'].str.split('/', expand=True)\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a new dataframe\ndff = pd.DataFrame()\ndff['Month'] = df['Month'].replace(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11','12'], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\ndff","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales = pd.concat([sales, dff], axis=1)\nsales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the 'Date' column\nsales.drop(['Date'], axis=1, inplace=True)\nsales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-ordering the columns\nsales = sales.reindex(columns=['State', 'Centre', 'Category', 'Commodity', 'Variety', 'Unit', 'Month', 'Retail Price'])\nprint(sales.shape)\nsales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grouping the rows and averaging the Retail Price\nsales = sales.groupby(['State', 'Centre', 'Commodity', 'Variety', 'Category', 'Unit', 'Month'], axis=0, as_index=False).mean()\n\nsales.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualizing the 'target' variable","metadata":{}},{"cell_type":"code","source":"sns.distplot(sales['Retail Price'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check if any more missing values present\nsales.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Correlation Matrix","metadata":{}},{"cell_type":"code","source":"# Correlation Matrix for the Numeric Columns\ncorr_matrix = sales.corr()\nplt.figure(figsize=(7,5))\nsns.heatmap(corr_matrix, annot=True, cmap = \"YlGnBu\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.drop('Retail Price', axis=1).corrwith(sales['Retail Price']).plot(kind='bar', grid=True, figsize=(7, 5), \n                                                                        title=\"Correlation with the target feature\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualizing the categorical variables","metadata":{}},{"cell_type":"code","source":"# check for categorical columns\ncat_col = []\nfor x in sales.dtypes.index:\n    if sales.dtypes[x] == 'object':\n        cat_col.append(x)\ncat_col","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.countplot(sales['Category'])\nplt.xticks(rotation=\"vertical\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.countplot(sales['Commodity'])\nplt.xticks(rotation=\"vertical\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.countplot(sales['Variety'])\nplt.xticks(rotation=\"vertical\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.countplot(sales['State'])\nplt.xticks(rotation=\"vertical\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.countplot(sales['Centre'])\nplt.xticks(rotation=\"vertical\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### One Hot Encoding","metadata":{}},{"cell_type":"code","source":"# One Hot Encoding -> new column for each category\ncategory = pd.get_dummies(sales['Category'])\ncategory.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To avoid dummy-variable trap, we should have 1 less dummies column\n# If all categories are 0, it will mean 'Misc' is 1, so we can safely drop it\ncategory = category.drop(['Misc'], axis='columns')\ncategory.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"variety = pd.get_dummies(sales['Variety'])\nvariety = variety.drop(['FAQ'], axis='columns')\nvariety.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"commodity = pd.get_dummies(sales['Commodity'], drop_first=True)\ncommodity.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state = pd.get_dummies(sales['State'], drop_first=True)\nstate.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"centre = pd.get_dummies(sales['Centre'], drop_first=True)\ncentre.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concat it into our main dataset\nsales = pd.concat([category, commodity, state, centre, variety, sales], axis='columns')\nsales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop off the extra columns now\nsales = sales.drop(['State', 'Category', 'Commodity', 'Centre', 'Variety'], axis='columns')\nsales.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for null values\nsales.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building our model","metadata":{}},{"cell_type":"code","source":"# Define the 'features' and 'labels'\nX = sales.drop('Retail Price', axis='columns')\ny = sales['Retail Price']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define train : test dataset in 70 : 30 ratio\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale down i/p features for better results\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear Regression model","metadata":{}},{"cell_type":"code","source":"# Import Linear Regression model\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\n\n# Train the model on the training set\nmodel.fit(X_train, y_train)\n\n# Make predictions on the testing set\ny_pred = model.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluating our model\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nprint(\"Mean absolute error: \", mean_absolute_error(y_test, y_pred))\nprint(\"Mean squared error: \", mean_squared_error(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nscore = r2_score(y_test, y_pred)*100\n\n# Create a dataframe to display accuracy\nresults_df = pd.DataFrame(data=[[\"Simple Linear Regression\", score]],\n                          columns=['Model', 'Accuracy(%)'])\nresults_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Regressor model ","metadata":{}},{"cell_type":"code","source":"# Import Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(n_estimators=100, random_state=0)\n\n# Train the model on the training set\nregressor.fit(X_train, y_train)\n\n# Make predictions on the testing set\ny_pred1 = regressor.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluating our regressor model\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nprint(\"Mean absolute error: \", mean_absolute_error(y_test, y_pred1))\nprint(\"Mean squared error: \", mean_squared_error(y_test, y_pred1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nscore = r2_score(y_test, y_pred1)*100\n\n# Create a dataframe to display accuracy\nresults_df1 = pd.DataFrame(data=[[\"Random Forest Regressor\", score]],\n                          columns=['Model', 'Accuracy(%)'])\nresults_df1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df = results_df.append(results_df1, ignore_index=True)\nresults_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost Regressor","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBRegressor\n\nxgb_reg = XGBRegressor(max_depth=5)\n\n# Train the model on the training set\nxgb_reg.fit(X_train, y_train)\n\n# Make predictions on the testing set\ny_pred2 = xgb_reg.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nscore = r2_score(y_test, y_pred2)*100\n\n# Create a dataframe to display accuracy\nresults_df2 = pd.DataFrame(data=[[\"XGBoost Regressor\", score]],\n                          columns=['Model', 'Accuracy(%)'])\nresults_df2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Hyperparameter tuning in XGBoost Regressor","metadata":{}},{"cell_type":"code","source":"# Hyperparameter tuning\nimport xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparam_grid = {\n        'max_depth': [4, 5, 6, 7],\n        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0,3, 1],\n        'subsample': [0.7, 0.8, 0.9, 1.0],\n        'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n        'colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0],\n        'min_child_weight': [0.5, 1.0, 3.0, 5.0],\n        'gamma': [0.25, 0.5, 1.0, 1.5],\n        'n_estimators': [100, 200, 500, 1000]}\n\nfit_params = {'eval_metric': 'mae',\n              'early_stopping_rounds': 10,\n              'eval_set': [(X_train, y_train)]}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBRegressor()\n\nxgb_cv = RandomizedSearchCV(xgb, param_grid, verbose=2, n_jobs=-1, scoring='neg_mean_absolute_error', cv=2)\n\n# Train the model on the training set\nxgb_cv.fit(X_train, y_train, **fit_params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_score = xgb_cv.best_score_\nbest_params = xgb_cv.best_params_\n\nprint(\"Best score: {}\".format(best_score))\nprint(\"Best parameters: \")\nfor param_name in sorted(best_params.keys()):\n    print('%s: %r' % (param_name, best_params[param_name]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### XGBoost with optimal hyperparameters ","metadata":{}},{"cell_type":"code","source":"# XGBoost with optimal hyperparameters\nxgb = XGBRegressor(gamma=0.25, learning_rate=0.2, max_depth=7, n_estimators=1000, subsample=0.9,\n                   colsample_bylevel=0.8, colsample_bytree=0.8, min_child_weight=3.0) \n\n# Train the model on the training set\nxgb.fit(X_train, y_train)\n\n# Make predictions on the testing set\ny_pred3 = xgb.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Score: \", xgb.score(X_test, y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluating our regressor model\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nprint(\"Mean absolute error: \", mean_absolute_error(y_test, y_pred3))\nprint(\"Mean squared error: \", mean_squared_error(y_test, y_pred3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nscore = r2_score(y_test, y_pred3)*100\n\n# Create a dataframe to display accuracy\nresults_df3 = pd.DataFrame(data=[[\"XGBoost Regressor\", score]],\n                          columns=['Model', 'Accuracy(%)'])\nresults_df3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clearly, Random Forest Regressor gave the best score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df = results_df.append(results_df3, ignore_index=True)\nresults_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making predictions","metadata":{}},{"cell_type":"code","source":"X.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_price(state, category, unit, month):\n    loc_index = np.where(X.columns==state)[0][0]\n    cat_index = np.where(X.columns==category)[0][0]\n    \n    x = np.zeros(len(X.columns))\n    x[199] = month\n    x[198] = unit\n    if loc_index >= 0:\n        x[loc_index] = 1\n    if cat_index >= 0:\n        x[cat_index] = 1\n\n    return xgb.predict([x])[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_price('Assam', 'Fruits', 1, 7)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred1 = regressor.predict(X_test)\npred2 = xgb.predict(X_test)\n\nfinal_pred = (pred1+pred2)/2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'Actual': y_test, 'Predicted': final_pred})\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = df['Predicted']\nfinal_df = df.drop('Actual', axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[\"Retail Price\"] = final_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"export_csv = X.to_csv(r'C:\\Users\\Rajashri\\Desktop\\Resume\\Resume Projects\\Sales prediction\\predictions.csv', \n                      index=None, header=True)\nprint(\"Successfully Exported!!\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}